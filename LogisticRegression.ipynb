{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_cleveland = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\")\n",
    "\n",
    "df_cleveland.drop(df_cleveland.columns[[-3,-4,-6,-8,-9]], axis = 1, inplace = True)\n",
    "df_cleveland.rename(columns = {'63.0':'age', '1.0':'sex', '1.0.1':'cp', '145.0':'trestbps', '233.0':'chol', '150.0':'thalach', '6.0':'thal', '2.3':'oldpeak','0':'num' }, inplace = True)\n",
    "\n",
    "df_cleveland['num'] = df_cleveland['num'].map({0:'0', 1:'0',2:'1',3:'1'})\n",
    "\n",
    "df_cleveland = df_cleveland.dropna(subset=['num'])\n",
    "df_cleveland['num'] = df_cleveland['num'].astype(int)\n",
    "\n",
    "df_cleveland.drop(df_cleveland[df_cleveland['thal'] == '?'].index, inplace = True)\n",
    "df_cleveland['thal'] = df_cleveland['thal'].astype(float)\n",
    "\n",
    "x = df_cleveland.iloc[0:301, 0:8]\n",
    "y = df_cleveland.iloc[0:301,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size = 0.7)\n",
    "my_model = LogisticRegression(solver='lbfgs', max_iter=10000)\n",
    "my_model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = my_model.predict(X_test)\n",
    "y_pred_probs = my_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc= roc_auc_score(y_test, y_pred_probs)*100\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"macro\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
